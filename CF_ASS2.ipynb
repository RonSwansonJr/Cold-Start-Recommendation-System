{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CF_ASS2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBNU4lCgB6f7"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7zM2A6rWNR8",
        "outputId": "34080ba0-50d8-45c8-e870-ea1131892d0c"
      },
      "source": [
        "df1 = pd.read_csv('u.data',sep='\\t',names=['user_id','item_id','rating','timestamp'])\r\n",
        "print(df1)\r\n",
        "#make user_id x item_it array\r\n",
        "#2d array --> 944 users x 1683 items\r\n",
        "ratings = np.empty(shape=(944,1683))\r\n",
        "ratings[:] = np.nan\r\n",
        "#copy training data(given ratings) into 2d array\r\n",
        "for i in range(df1.shape[0]):\r\n",
        "  #print(i)\r\n",
        "  temp = df1.iloc[[i]]\r\n",
        "  ratings[temp['user_id'][i]][temp['item_id'][i]] = temp['rating'][i]\r\n",
        "print('copied')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       user_id  item_id  rating  timestamp\n",
            "0          196      242       3  881250949\n",
            "1          186      302       3  891717742\n",
            "2           22      377       1  878887116\n",
            "3          244       51       2  880606923\n",
            "4          166      346       1  886397596\n",
            "...        ...      ...     ...        ...\n",
            "99995      880      476       3  880175444\n",
            "99996      716      204       5  879795543\n",
            "99997      276     1090       1  874795795\n",
            "99998       13      225       2  882399156\n",
            "99999       12      203       3  879959583\n",
            "\n",
            "[100000 rows x 4 columns]\n",
            "copied\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "lJa1US-PFHpk",
        "outputId": "f17db924-4c62-4d2b-8e9d-72102eca8f67"
      },
      "source": [
        "#convert categorical columns into numbers\r\n",
        "train = pd.read_csv('u.user',sep='|',names=['user_id','age','sex','occupation','zip'])#names=['user_id','item_id','rating','timestamp'])\r\n",
        "train['zip'].value_counts()\r\n",
        "\r\n",
        "train['sex'] = train['sex'].astype('category')\r\n",
        "train['sex'] = train['sex'].cat.codes\r\n",
        "train['occupation'] = train['occupation'].astype('category').cat.codes\r\n",
        "train['zip'] = train['zip'].astype('category').cat.codes\r\n",
        "train"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>occupation</th>\n",
              "      <th>zip</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>938</th>\n",
              "      <td>939</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>940</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>940</th>\n",
              "      <td>941</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>942</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>942</th>\n",
              "      <td>943</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>561</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>943 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     user_id  age  sex  occupation  zip\n",
              "0          1   24    1          19  622\n",
              "1          2   53    0          13  689\n",
              "2          3   23    1          20  270\n",
              "3          4   24    1          19  331\n",
              "4          5   33    0          13  133\n",
              "..       ...  ...  ...         ...  ...\n",
              "938      939   26    0          18  282\n",
              "939      940   32    1           0   31\n",
              "940      941   20    1          18  743\n",
              "941      942   48    0          10  566\n",
              "942      943   22    1          18  561\n",
              "\n",
              "[943 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7BynD19FXGF"
      },
      "source": [
        "#create 5 folds, train_fi ---> means train of ith fold\r\n",
        "test_f1 = train.iloc[0:101]\r\n",
        "train_f1 = train.iloc[101:]\r\n",
        "train_f1.reset_index(drop=True,inplace=True)\r\n",
        "#fold 2 \r\n",
        "test_f2= train[0:91]\r\n",
        "train_f2 = train[91:]\r\n",
        "#fold 3 \r\n",
        "test_f3= train[0:81]\r\n",
        "train_f3 = train[81:]\r\n",
        "#fold 4 \r\n",
        "test_f4= train[0:71]\r\n",
        "train_f4 = train[71:]\r\n",
        "#fold 5 \r\n",
        "test_f5= train[0:61]\r\n",
        "train_f5 = train[61:]\r\n",
        "train_f3.reset_index(drop=True,inplace=True)\r\n",
        "train_f2.reset_index(drop=True,inplace=True)\r\n",
        "train_f4.reset_index(drop=True,inplace=True)\r\n",
        "train_f5.reset_index(drop=True,inplace=True)\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIbP4dxLRorX",
        "outputId": "3c9f1636-8ecf-46ad-c966-3b6f8690d1a6"
      },
      "source": [
        "test_f1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(101, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "EoCjFM1iVbTP",
        "outputId": "b06eb330-f3a1-4f97-847f-1f2fa2c67793"
      },
      "source": [
        "train_f3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>occupation</th>\n",
              "      <th>zip</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>82</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>83</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>85</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>86</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857</th>\n",
              "      <td>939</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>858</th>\n",
              "      <td>940</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>859</th>\n",
              "      <td>941</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>942</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>861</th>\n",
              "      <td>943</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>561</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>862 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     user_id  age  sex  occupation  zip\n",
              "0         82   50    1          14  207\n",
              "1         83   40    1          13  336\n",
              "2         84   32    1           6  433\n",
              "3         85   51    1           3  169\n",
              "4         86   26    1           0  350\n",
              "..       ...  ...  ...         ...  ...\n",
              "857      939   26    0          18  282\n",
              "858      940   32    1           0   31\n",
              "859      941   20    1          18  743\n",
              "860      942   48    0          10  566\n",
              "861      943   22    1          18  561\n",
              "\n",
              "[862 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu0VP7FwGqtz",
        "outputId": "08cfb1a7-0ea6-4e71-e960-2e519a0b105e"
      },
      "source": [
        "#kmeans with euclidean dist\r\n",
        "#from sklearn doc\r\n",
        "#-----------------------fold1---------------------\r\n",
        "from sklearn.cluster import KMeans \r\n",
        "\r\n",
        "fitted_model = KMeans(n_clusters=20, random_state=0).fit(train_f1)\r\n",
        "\r\n",
        "#train_cluster_index has the cluster numbers for the training data(users)\r\n",
        "train_cluster_index = fitted_model.predict(train_f1)\r\n",
        "#test_cluster_index has the cluster numbers for the test data(users)\r\n",
        "test_cluster_index = fitted_model.predict(test_f1)\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f1.shape[0]+1):\r\n",
        "  #for each item J\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    #go through each training user \r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #found user at index k in our cluster\r\n",
        "        #get user_id of user at index k \r\n",
        "        user_id = train_f1['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          #if our neighbour in our cluster has rated item J then use in finding average\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    #initialize predicted rating as 3 to minimize mae\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 1 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#same thing for fold 2 only thing is train_f1 is replaced by train_f2 and test_f1-->test_f2\r\n",
        "#repeat for 5 folds\r\n",
        "#-------------fold2--------------\r\n",
        "\r\n",
        "fitted_model = KMeans(n_clusters=20, random_state=0).fit(train_f2)\r\n",
        "train_cluster_index = fitted_model.predict(train_f2)\r\n",
        "test_cluster_index = fitted_model.predict(test_f2)\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(1,test_f2.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f2['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 2 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#-----------------fold3--------------------\r\n",
        "\r\n",
        "fitted_model = KMeans(n_clusters=20, random_state=0).fit(train_f3)\r\n",
        "train_cluster_index = fitted_model.predict(train_f3)\r\n",
        "test_cluster_index = fitted_model.predict(test_f3)\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(1,test_f3.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f3['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 3 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#------fold 4--------------\r\n",
        "\r\n",
        "fitted_model = KMeans(n_clusters=20, random_state=0).fit(train_f4)\r\n",
        "train_cluster_index = fitted_model.predict(train_f4)\r\n",
        "test_cluster_index = fitted_model.predict(test_f4)\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(1,test_f4.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f4['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 4 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#----------F5---------\r\n",
        "\r\n",
        "fitted_model = KMeans(n_clusters=20, random_state=0).fit(train_f5)\r\n",
        "train_cluster_index = fitted_model.predict(train_f5)\r\n",
        "test_cluster_index = fitted_model.predict(test_f5)\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(1,test_f5.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f5['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 5 : ',mae_sum/mae_cnt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mae Fold 1 :  0.8761332637780882\n",
            "Mae Fold 2 :  0.8933536603169839\n",
            "Mae Fold 3 :  0.887355867817912\n",
            "Mae Fold 4 :  0.8837678811146912\n",
            "Mae Fold 5 :  0.9038970862476037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDRUBTPPXii2",
        "outputId": "b5a349b7-2bb5-494e-e151-d93cddd79c07"
      },
      "source": [
        "#mean shift clustering - uses rbf kernel with centroids\r\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MeanShift.html#sklearn.cluster.MeanShift\r\n",
        "from sklearn.cluster import MeanShift\r\n",
        "\r\n",
        "#-------------fold1-----------------\r\n",
        "#same as before but only fitted_model is different, here we use meanshift \r\n",
        "# rest all same\r\n",
        "fitted_model = MeanShift(bandwidth=10).fit(train_f1)\r\n",
        "train_cluster_index = fitted_model.predict(train_f1)\r\n",
        "test_cluster_index = fitted_model.predict(test_f1)\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f1.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f1['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 1 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "#------------------------fold2------------\r\n",
        "#all folds same as fold 1 so no need to explain\r\n",
        "fitted_model = MeanShift(bandwidth=10).fit(train_f2)\r\n",
        "train_cluster_index = fitted_model.predict(train_f2)\r\n",
        "test_cluster_index = fitted_model.predict(test_f2)\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f2.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f2['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 2 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#----------------fold3------------\r\n",
        "#fold1\r\n",
        "fitted_model = MeanShift(bandwidth=10).fit(train_f3)\r\n",
        "train_cluster_index = fitted_model.predict(train_f3)\r\n",
        "test_cluster_index = fitted_model.predict(test_f3)\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f3.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f3['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 3 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#----------fold4----------------\r\n",
        "\r\n",
        "fitted_model = MeanShift(bandwidth=10).fit(train_f4)\r\n",
        "train_cluster_index = fitted_model.predict(train_f4)\r\n",
        "test_cluster_index = fitted_model.predict(test_f4)\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f4.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f4['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 4 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#fold5---------------------------\r\n",
        "\r\n",
        "fitted_model = MeanShift(bandwidth=10).fit(train_f5)\r\n",
        "train_cluster_index = fitted_model.predict(train_f5)\r\n",
        "test_cluster_index = fitted_model.predict(test_f5)\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f5.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f5['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 5 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mae Fold 1 :  1.0579559805159662\n",
            "Mae Fold 2 :  1.0662531276063387\n",
            "Mae Fold 3 :  1.0668377321603129\n",
            "Mae Fold 4 :  1.0624171746620725\n",
            "Mae Fold 5 :  1.0572293716881151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU49QIT_zuhf"
      },
      "source": [
        "# dropping user_id column and calling it train_fino denoting training data for ith fold but no user id\r\n",
        "train_f1no = train_f1.drop(['user_id'],axis=1)\r\n",
        "test_f1no = test_f1.drop(['user_id'],axis=1)\r\n",
        "train_f2no = train_f2.drop(['user_id'],axis=1)\r\n",
        "test_f2no = test_f2.drop(['user_id'],axis=1)\r\n",
        "train_f3no = train_f3.drop(['user_id'],axis=1)\r\n",
        "test_f3no = test_f3.drop(['user_id'],axis=1)\r\n",
        "train_f4no = train_f4.drop(['user_id'],axis=1)\r\n",
        "test_f4no = test_f4.drop(['user_id'],axis=1)\r\n",
        "train_f5no = train_f5.drop(['user_id'],axis=1)\r\n",
        "test_f5no = test_f5.drop(['user_id'],axis=1)\r\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yswApnfKCDWX",
        "outputId": "b4c248d1-4c5a-42b6-c888-76b1c898e234"
      },
      "source": [
        "#k means from scratch with kernel - rbf\r\n",
        "#-----------fold1--------------------\r\n",
        "from sklearn.metrics.pairwise import pairwise_kernels\r\n",
        "\r\n",
        "#to store cluster numbers of training data\r\n",
        "train_labels = np.empty((train_f1no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "#initialize the 10 centroids by choosing first 10 points\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f1no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f1no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f1no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f1no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "print(cluster_centroids[0])\r\n",
        "#iterate 1000 times\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity, gives us similarity matrix\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f1no,Y=np.array(cluster_centroids),metric='rbf')\r\n",
        "  #similarity_mat[i][j] is similarity between ith datapoint in trainf1_no and j th cluster (cluster number j+1)\r\n",
        "  for i in range(train_f1no.shape[0]):\r\n",
        "    #for each user find most similar centroid\r\n",
        "    max_sim = max(similarity_mat[i])#most similar centroid for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroids by taking centroid = avg of all columns of all vectors in current cluster\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f1no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        #if this user is in kth cluster,use in average computation\r\n",
        "        cnt+=1\r\n",
        "        #add user I's data to calculate average\r\n",
        "        sum_arr[0]+=(train_f1no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f1no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f1no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f1no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        #changing centroid to the newly computed ones\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "#now clusters and centroids computed,find out which cluster is closest to each test point\r\n",
        "#assign new rating as avg rating of all users in closest cluster\r\n",
        "similarity_mat = pairwise_kernels(X=test_f1no,Y=np.array(cluster_centroids),metric='rbf')\r\n",
        "#similarity between test and centroids\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#for each test point\r\n",
        "for i in range(test_f1no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f1['user_id'][i]][j])==True):\r\n",
        "      #ignore unrated items\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    #calculate avg rating of users in best cluster (cluster closest to user I)\r\n",
        "    for u in range(train_f1.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        #user u is user I's neighbour (same cluster)\r\n",
        "        if(np.isnan(ratings[train_f1['user_id'][u]][j])==True):\r\n",
        "          #ignore if unrated\r\n",
        "          continue\r\n",
        "        #calculate average\r\n",
        "        avg_sum+=ratings[train_f1['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # calc mae\r\n",
        "    mae_sum+=abs(ratings[test_f1['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 1 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#--------------fold2---------------------------\r\n",
        "#same as above only different dataset\r\n",
        "#train_f2no instead of train_f1no\r\n",
        "\r\n",
        "train_labels = np.empty((train_f2no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f2no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f2no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f2no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f2no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "print(cluster_centroids[0])\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f2no,Y=np.array(cluster_centroids),metric='rbf')\r\n",
        "  for i in range(train_f2no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f2no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f2no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f2no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f2no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f2no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f2no = test_f2.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f2no,Y=np.array(cluster_centroids),metric='rbf')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f2no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f2['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f2.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f2['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f2['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f2['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 2 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "#-----------fold3--------------------\r\n",
        "\r\n",
        "\r\n",
        "train_f3no = train_f3.drop(['user_id'],axis=1)\r\n",
        "train_labels = np.empty((train_f3no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f3no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f3no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f3no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f3no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "print(cluster_centroids[0])\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f3no,Y=np.array(cluster_centroids),metric='rbf')\r\n",
        "  for i in range(train_f3no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f3no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f3no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f3no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f3no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f3no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f3no = test_f3.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f3no,Y=np.array(cluster_centroids),metric='rbf')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f3no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f3['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f3.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f3['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f3['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f3['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 3 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "#-----------fold4--------------------\r\n",
        "\r\n",
        "train_f4no = train_f4.drop(['user_id'],axis=1)\r\n",
        "train_labels = np.empty((train_f4no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f4no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f4no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f4no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f4no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "print(cluster_centroids[0])\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f4no,Y=np.array(cluster_centroids),metric='rbf')\r\n",
        "  for i in range(train_f4no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f4no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f4no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f4no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f4no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f4no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f4no = test_f4.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f4no,Y=np.array(cluster_centroids),metric='rbf')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f4no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f4['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f4.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f4['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f4['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f4['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 4 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#-----------fold5--------------------\r\n",
        "\r\n",
        "\r\n",
        "train_f5no = train_f5.drop(['user_id'],axis=1)\r\n",
        "train_labels = np.empty((train_f5no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f5no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f5no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f5no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f5no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "print(cluster_centroids[0])\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f5no,Y=np.array(cluster_centroids),metric='rbf')\r\n",
        "  for i in range(train_f5no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f5no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f5no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f5no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f5no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f5no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f5no = test_f5.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f5no,Y=np.array(cluster_centroids),metric='rbf')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f5no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f5['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f5.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f5['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f5['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f5['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 5 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    \r\n",
        "    \r\n",
        "      \r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[38, 1, 14, 261]\n",
            "fold 1 mae :  0.8463183616942396\n",
            "[32, 1, 5, 591]\n",
            "fold 2 mae :  0.8491217433037755\n",
            "[50, 1, 14, 207]\n",
            "fold 3 mae :  0.864353685266646\n",
            "[48, 0, 0, 527]\n",
            "fold 4 mae :  0.8701899205934366\n",
            "[27, 0, 0, 741]\n",
            "fold 5 mae :  0.8741941092163947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNTxyuWH2LXL",
        "outputId": "c314e290-031b-45ef-b1a9-aa1af1111311"
      },
      "source": [
        "#kernel k means scratch - laplacian\r\n",
        "#same as above but we change metric in kernel function to laplacian\r\n",
        "#-----------fold1--------------------\r\n",
        "train_f1no = train_f1.drop(['user_id'],axis=1)\r\n",
        "train_labels = np.empty((train_f1no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f1no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f1no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f1no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f1no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f1no,Y=np.array(cluster_centroids),metric='laplacian')\r\n",
        "  for i in range(train_f1no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f1no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f1no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f1no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f1no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f1no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f1no = test_f1.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f1no,Y=np.array(cluster_centroids),metric='laplacian')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f1no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f1['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f1.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f1['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f1['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f1['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 1 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#--------------fold2---------------------------\r\n",
        "\r\n",
        "\r\n",
        "train_f2no = train_f2.drop(['user_id'],axis=1)\r\n",
        "train_labels = np.empty((train_f2no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f2no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f2no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f2no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f2no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "print(cluster_centroids[0])\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f2no,Y=np.array(cluster_centroids),metric='laplacian')\r\n",
        "  for i in range(train_f2no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f2no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f2no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f2no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f2no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f2no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f2no = test_f2.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f2no,Y=np.array(cluster_centroids),metric='laplacian')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f2no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f2['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f2.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f2['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f2['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f2['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 2 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "#-----------fold3--------------------\r\n",
        "\r\n",
        "\r\n",
        "train_f3no = train_f3.drop(['user_id'],axis=1)\r\n",
        "train_labels = np.empty((train_f3no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f3no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f3no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f3no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f3no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "print(cluster_centroids[0])\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f3no,Y=np.array(cluster_centroids),metric='laplacian')\r\n",
        "  for i in range(train_f3no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f3no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f3no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f3no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f3no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f3no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f3no = test_f3.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f3no,Y=np.array(cluster_centroids),metric='laplacian')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f3no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f3['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f3.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f3['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f3['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f3['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 3 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "#-----------fold4--------------------\r\n",
        "\r\n",
        "train_f4no = train_f4.drop(['user_id'],axis=1)\r\n",
        "train_labels = np.empty((train_f4no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f4no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f4no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f4no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f4no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "print(cluster_centroids[0])\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f4no,Y=np.array(cluster_centroids),metric='laplacian')\r\n",
        "  for i in range(train_f4no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f4no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f4no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f4no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f4no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f4no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f4no = test_f4.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f4no,Y=np.array(cluster_centroids),metric='laplacian')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f4no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f4['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f4.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f4['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f4['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f4['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 4 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#-----------fold5--------------------\r\n",
        "\r\n",
        "\r\n",
        "train_f5no = train_f5.drop(['user_id'],axis=1)\r\n",
        "train_labels = np.empty((train_f5no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f5no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f5no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f5no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f5no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "print(cluster_centroids[0])\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f5no,Y=np.array(cluster_centroids),metric='laplacian')\r\n",
        "  for i in range(train_f5no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f5no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f5no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f5no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f5no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f5no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f5no = test_f5.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f5no,Y=np.array(cluster_centroids),metric='laplacian')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f5no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f5['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f5.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f5['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f5['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f5['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 5 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "   \r\n",
        "        \r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 1 mae :  0.8509463755286631\n",
            "[32, 1, 5, 591]\n",
            "fold 2 mae :  0.8522622501801788\n",
            "[50, 1, 14, 207]\n",
            "fold 3 mae :  0.8703823609234372\n",
            "[48, 0, 0, 527]\n",
            "fold 4 mae :  0.8718060828924221\n",
            "[27, 0, 0, 741]\n",
            "fold 5 mae :  0.8838848236364114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbG6QRXXjIIj",
        "outputId": "32f325eb-8a56-44ac-d1f1-538b549c4c2e"
      },
      "source": [
        "#kernel k means scratch - chi2\r\n",
        "#same as above but we change metric in kernel function to chi2\r\n",
        "#-----------fold1--------------------\r\n",
        "train_f1no = train_f1.drop(['user_id'],axis=1)\r\n",
        "train_labels = np.empty((train_f1no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f1no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f1no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f1no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f1no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f1no,Y=np.array(cluster_centroids),metric='chi2')\r\n",
        "  for i in range(train_f1no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f1no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f1no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f1no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f1no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f1no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f1no = test_f1.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f1no,Y=np.array(cluster_centroids),metric='chi2')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f1no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f1['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f1.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f1['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f1['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f1['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 1 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#--------------fold2---------------------------\r\n",
        "\r\n",
        "\r\n",
        "train_f2no = train_f2.drop(['user_id'],axis=1)\r\n",
        "train_labels = np.empty((train_f2no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f2no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f2no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f2no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f2no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "print(cluster_centroids[0])\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f2no,Y=np.array(cluster_centroids),metric='chi2')\r\n",
        "  for i in range(train_f2no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f2no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f2no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f2no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f2no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f2no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f2no = test_f2.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f2no,Y=np.array(cluster_centroids),metric='chi2')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f2no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f2['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f2.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f2['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f2['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f2['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 2 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "#-----------fold3--------------------\r\n",
        "\r\n",
        "\r\n",
        "train_f3no = train_f3.drop(['user_id'],axis=1)\r\n",
        "train_labels = np.empty((train_f3no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f3no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f3no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f3no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f3no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "print(cluster_centroids[0])\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f3no,Y=np.array(cluster_centroids),metric='chi2')\r\n",
        "  for i in range(train_f3no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f3no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f3no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f3no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f3no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f3no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f3no = test_f3.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f3no,Y=np.array(cluster_centroids),metric='chi2')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f3no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f3['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f3.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f3['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f3['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f3['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 3 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "#-----------fold4--------------------\r\n",
        "\r\n",
        "train_f4no = train_f4.drop(['user_id'],axis=1)\r\n",
        "train_labels = np.empty((train_f4no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f4no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f4no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f4no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f4no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "print(cluster_centroids[0])\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f4no,Y=np.array(cluster_centroids),metric='chi2')\r\n",
        "  for i in range(train_f4no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f4no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f4no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f4no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f4no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f4no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f4no = test_f4.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f4no,Y=np.array(cluster_centroids),metric='chi2')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f4no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f4['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f4.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f4['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f4['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f4['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 4 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#-----------fold5--------------------\r\n",
        "\r\n",
        "\r\n",
        "train_f5no = train_f5.drop(['user_id'],axis=1)\r\n",
        "train_labels = np.empty((train_f5no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f5no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f5no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f5no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f5no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "print(cluster_centroids[0])\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f5no,Y=np.array(cluster_centroids),metric='chi2')\r\n",
        "  for i in range(train_f5no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f5no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f5no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f5no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f5no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f5no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f5no = test_f5.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f5no,Y=np.array(cluster_centroids),metric='chi2')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f5no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f5['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f5.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f5['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f5['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f5['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 5 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "   \r\n",
        "        \r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 1 mae :  0.8403788967637624\n",
            "[32, 1, 5, 591]\n",
            "fold 2 mae :  0.8550987035835975\n",
            "[50, 1, 14, 207]\n",
            "fold 3 mae :  0.8687279173753859\n",
            "[48, 0, 0, 527]\n",
            "fold 4 mae :  0.8627886987070171\n",
            "[27, 0, 0, 741]\n",
            "fold 5 mae :  0.8724494291596149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ad6OyEaUkpWR",
        "outputId": "a455da9c-4ebd-4e38-deb8-223c9cab2393"
      },
      "source": [
        "#kernel k means scratch - additive_chi\r\n",
        "#same as above but we change metric in kernel function to additive_chi2\r\n",
        "#-----------fold1--------------------\r\n",
        "train_f1no = train_f1.drop(['user_id'],axis=1)\r\n",
        "train_labels = np.empty((train_f1no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f1no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f1no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f1no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f1no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f1no,Y=np.array(cluster_centroids),metric='additive_chi2')\r\n",
        "  for i in range(train_f1no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f1no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f1no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f1no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f1no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f1no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f1no = test_f1.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f1no,Y=np.array(cluster_centroids),metric='additive_chi2')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f1no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f1['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f1.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f1['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f1['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f1['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 1 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#--------------fold2---------------------------\r\n",
        "\r\n",
        "\r\n",
        "train_f2no = train_f2.drop(['user_id'],axis=1)\r\n",
        "train_labels = np.empty((train_f2no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f2no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f2no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f2no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f2no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "print(cluster_centroids[0])\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f2no,Y=np.array(cluster_centroids),metric='additive_chi2')\r\n",
        "  for i in range(train_f2no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f2no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f2no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f2no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f2no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f2no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f2no = test_f2.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f2no,Y=np.array(cluster_centroids),metric='additive_chi2')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f2no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f2['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f2.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f2['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f2['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f2['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 2 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "#-----------fold3--------------------\r\n",
        "\r\n",
        "\r\n",
        "train_f3no = train_f3.drop(['user_id'],axis=1)\r\n",
        "train_labels = np.empty((train_f3no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f3no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f3no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f3no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f3no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "print(cluster_centroids[0])\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f3no,Y=np.array(cluster_centroids),metric='additive_chi2')\r\n",
        "  for i in range(train_f3no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f3no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f3no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f3no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f3no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f3no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f3no = test_f3.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f3no,Y=np.array(cluster_centroids),metric='additive_chi2')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f3no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f3['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f3.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f3['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f3['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f3['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 3 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "#-----------fold4--------------------\r\n",
        "\r\n",
        "train_f4no = train_f4.drop(['user_id'],axis=1)\r\n",
        "train_labels = np.empty((train_f4no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f4no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f4no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f4no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f4no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "print(cluster_centroids[0])\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f4no,Y=np.array(cluster_centroids),metric='additive_chi2')\r\n",
        "  for i in range(train_f4no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f4no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f4no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f4no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f4no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f4no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f4no = test_f4.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f4no,Y=np.array(cluster_centroids),metric='additive_chi2')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f4no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f4['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f4.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f4['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f4['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f4['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 4 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#-----------fold5--------------------\r\n",
        "\r\n",
        "\r\n",
        "train_f5no = train_f5.drop(['user_id'],axis=1)\r\n",
        "train_labels = np.empty((train_f5no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f5no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f5no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f5no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f5no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "print(cluster_centroids[0])\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f5no,Y=np.array(cluster_centroids),metric='additive_chi2')\r\n",
        "  for i in range(train_f5no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f5no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f5no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f5no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f5no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f5no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f5no = test_f5.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f5no,Y=np.array(cluster_centroids),metric='additive_chi2')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f5no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f5['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f5.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f5['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f5['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f5['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 5 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "   \r\n",
        "        \r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 1 mae :  0.8403788967637624\n",
            "[32, 1, 5, 591]\n",
            "fold 2 mae :  0.8550987035835975\n",
            "[50, 1, 14, 207]\n",
            "fold 3 mae :  0.8687279173753859\n",
            "[48, 0, 0, 527]\n",
            "fold 4 mae :  0.8627886987070171\n",
            "[27, 0, 0, 741]\n",
            "fold 5 mae :  0.8724494291596149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_5WXEBXmd7I",
        "outputId": "f163214e-9356-432c-acb4-ef5c32a91323"
      },
      "source": [
        "#kernel k means scratch - cosine\r\n",
        "#same as above but we change metric in kernel function to cosine\r\n",
        "#-----------fold1--------------------\r\n",
        "train_f1no = train_f1.drop(['user_id'],axis=1)\r\n",
        "train_labels = np.empty((train_f1no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f1no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f1no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f1no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f1no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f1no,Y=np.array(cluster_centroids),metric='cosine')\r\n",
        "  for i in range(train_f1no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f1no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f1no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f1no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f1no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f1no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f1no = test_f1.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f1no,Y=np.array(cluster_centroids),metric='cosine')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f1no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f1['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f1.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f1['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f1['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f1['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 1 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#--------------fold2---------------------------\r\n",
        "\r\n",
        "\r\n",
        "train_f2no = train_f2.drop(['user_id'],axis=1)\r\n",
        "train_labels = np.empty((train_f2no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f2no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f2no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f2no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f2no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "print(cluster_centroids[0])\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f2no,Y=np.array(cluster_centroids),metric='cosine')\r\n",
        "  for i in range(train_f2no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f2no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f2no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f2no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f2no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f2no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f2no = test_f2.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f2no,Y=np.array(cluster_centroids),metric='cosine')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f2no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f2['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f2.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f2['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f2['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f2['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 2 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "#-----------fold3--------------------\r\n",
        "\r\n",
        "\r\n",
        "train_f3no = train_f3.drop(['user_id'],axis=1)\r\n",
        "train_labels = np.empty((train_f3no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f3no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f3no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f3no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f3no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "print(cluster_centroids[0])\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f3no,Y=np.array(cluster_centroids),metric='cosine')\r\n",
        "  for i in range(train_f3no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f3no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f3no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f3no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f3no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f3no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f3no = test_f3.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f3no,Y=np.array(cluster_centroids),metric='cosine')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f3no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f3['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f3.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f3['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f3['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f3['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 3 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "#-----------fold4--------------------\r\n",
        "\r\n",
        "train_f4no = train_f4.drop(['user_id'],axis=1)\r\n",
        "train_labels = np.empty((train_f4no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f4no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f4no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f4no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f4no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "print(cluster_centroids[0])\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f4no,Y=np.array(cluster_centroids),metric='cosine')\r\n",
        "  for i in range(train_f4no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f4no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f4no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f4no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f4no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f4no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f4no = test_f4.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f4no,Y=np.array(cluster_centroids),metric='cosine')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f4no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f4['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f4.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f4['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f4['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f4['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 4 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#-----------fold5--------------------\r\n",
        "\r\n",
        "\r\n",
        "train_f5no = train_f5.drop(['user_id'],axis=1)\r\n",
        "train_labels = np.empty((train_f5no.shape[0],))\r\n",
        "train_labels[:] = -1# labels will be 1 to 10\r\n",
        "#10 centroids\r\n",
        "cluster_centroids = []\r\n",
        "for i in range(10):\r\n",
        "  cluster = []\r\n",
        "  cluster.append(train_f5no.iloc[[i]]['age'][i])\r\n",
        "  cluster.append(train_f5no.iloc[[i]]['sex'][i])\r\n",
        "  cluster.append(train_f5no.iloc[[i]]['occupation'][i])\r\n",
        "  cluster.append(train_f5no.iloc[[i]]['zip'][i])\r\n",
        "  cluster_centroids.append(cluster)\r\n",
        "\r\n",
        "print(cluster_centroids[0])\r\n",
        "for iter in range(1000):\r\n",
        "  #assign clusters to train\r\n",
        "  #calculate kernel similarity\r\n",
        "  similarity_mat = pairwise_kernels(X=train_f5no,Y=np.array(cluster_centroids),metric='cosine')\r\n",
        "  for i in range(train_f5no.shape[0]):\r\n",
        "    max_sim = max(similarity_mat[i])#most similar cluster for user I\r\n",
        "    for j in range(10):\r\n",
        "      if(similarity_mat[i][j]==max_sim):\r\n",
        "        #assign user I to cluster J\r\n",
        "        train_labels[i] = j+1\r\n",
        "        break\r\n",
        "  #recompute centroid\r\n",
        "  for k in range(10):\r\n",
        "    sum_arr = [0]*4\r\n",
        "    cnt=0\r\n",
        "    for i in range(train_f5no.shape[0]):\r\n",
        "      if(train_labels[i]==(k+1)):\r\n",
        "        cnt+=1\r\n",
        "        #choose user I as part of cluster (k+1)\r\n",
        "        sum_arr[0]+=(train_f5no['age'][i])\r\n",
        "        sum_arr[1]+=(train_f5no['sex'][i])\r\n",
        "        sum_arr[2]+=(train_f5no['occupation'][i])\r\n",
        "        sum_arr[3]+=(train_f5no['zip'][i])\r\n",
        "    if(cnt>0):\r\n",
        "      for l in range(4):\r\n",
        "        cluster_centroids[k][l] = sum_arr[l]/cnt\r\n",
        "\r\n",
        "test_f5no = test_f5.drop(['user_id'],axis=1)\r\n",
        "similarity_mat = pairwise_kernels(X=test_f5no,Y=np.array(cluster_centroids),metric='cosine')\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(test_f5no.shape[0]):\r\n",
        "  best_cluster = max(similarity_mat[i])\r\n",
        "  cluster_num = 0\r\n",
        "  for k in range(10):\r\n",
        "    if(similarity_mat[i][k]==best_cluster):\r\n",
        "      #user I assign to cluster k+1\r\n",
        "      cluster_num = k+1\r\n",
        "      break\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[test_f5['user_id'][i]][j])==True):\r\n",
        "      continue\r\n",
        "    avg_sum=0\r\n",
        "    avg_cnt=0\r\n",
        "    for u in range(train_f5.shape[0]):\r\n",
        "      if(train_labels[u] == cluster_num):\r\n",
        "        if(np.isnan(ratings[train_f5['user_id'][u]][j])==True):\r\n",
        "          continue\r\n",
        "        avg_sum+=ratings[train_f5['user_id'][u]][j]\r\n",
        "        avg_cnt+=1\r\n",
        "    predicted_rating=3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_sum/avg_cnt\r\n",
        "    # print(predicted_rating)\r\n",
        "    mae_sum+=abs(ratings[test_f5['user_id'][i]][j] - predicted_rating)\r\n",
        "    mae_cnt+=1\r\n",
        "print('fold 5 mae : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "   \r\n",
        "        \r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 1 mae :  0.8504369334077472\n",
            "[32, 1, 5, 591]\n",
            "fold 2 mae :  0.8601844649429699\n",
            "[50, 1, 14, 207]\n",
            "fold 3 mae :  0.8724292656467519\n",
            "[48, 0, 0, 527]\n",
            "fold 4 mae :  0.8591190766469655\n",
            "[27, 0, 0, 741]\n",
            "fold 5 mae :  0.8868980625589301\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7yHbhzq9szz",
        "outputId": "8089e3dd-d278-4ff8-9034-8ece033e192f"
      },
      "source": [
        "#agglomerative clustering manhattan\r\n",
        "from sklearn.cluster import AgglomerativeClustering\r\n",
        "#from sklearn doc\r\n",
        "#----fold1---------\r\n",
        "#same as normal k means , but different model\r\n",
        "total_labels = AgglomerativeClustering(n_clusters=10,affinity='manhattan',linkage='average').fit_predict(train_f1no.append(test_f1no,ignore_index=True))\r\n",
        "\r\n",
        "#stores cluster number of train and test respectivily\r\n",
        "train_cluster_index = total_labels[0:train_f1no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f1no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#all this already explained\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f1.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f1['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 1 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#----fold2---------\r\n",
        "\r\n",
        "total_labels = AgglomerativeClustering(n_clusters=10,affinity='manhattan',linkage='average').fit_predict(train_f2no.append(test_f2no,ignore_index=True))\r\n",
        "\r\n",
        "train_cluster_index = total_labels[0:train_f2no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f2no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f2.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f2['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 2 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "#----fold3---------\r\n",
        "total_labels = AgglomerativeClustering(n_clusters=10,affinity='manhattan',linkage='average').fit_predict(train_f3no.append(test_f3no,ignore_index=True))\r\n",
        "\r\n",
        "train_cluster_index = total_labels[0:train_f3no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f3no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f3.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f3['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 3 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#----fold4---------\r\n",
        "total_labels = AgglomerativeClustering(n_clusters=10,affinity='manhattan',linkage='average').fit_predict(train_f4no.append(test_f4no,ignore_index=True))\r\n",
        "\r\n",
        "train_cluster_index = total_labels[0:train_f4no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f4no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f4.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f4['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 4 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "#----fold5---------\r\n",
        "total_labels = AgglomerativeClustering(n_clusters=10,affinity='manhattan',linkage='average').fit_predict(train_f5no.append(test_f5no,ignore_index=True))\r\n",
        "\r\n",
        "train_cluster_index = total_labels[0:train_f5no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f5no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f5.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f5['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 5 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mae Fold 1 :  0.8436984276533\n",
            "Mae Fold 2 :  0.8535159183588656\n",
            "Mae Fold 3 :  0.8651153147893279\n",
            "Mae Fold 4 :  0.8660461830369446\n",
            "Mae Fold 5 :  0.8821614520752755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uniaC0MutX_H",
        "outputId": "1c3165b1-3028-4e6c-f09b-6fc4cc6ca5b2"
      },
      "source": [
        "#agglomerative clustering l1 norm\r\n",
        "from sklearn.cluster import AgglomerativeClustering\r\n",
        "\r\n",
        "#----fold1---------\r\n",
        "total_labels = AgglomerativeClustering(n_clusters=10,affinity='l1',linkage='single').fit_predict(train_f1no.append(test_f1no,ignore_index=True))\r\n",
        "\r\n",
        "train_cluster_index = total_labels[0:train_f1no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f1no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f1.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f1['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 1 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#----fold2---------\r\n",
        "\r\n",
        "total_labels = AgglomerativeClustering(n_clusters=10,affinity='l1',linkage='single').fit_predict(train_f2no.append(test_f2no,ignore_index=True))\r\n",
        "\r\n",
        "train_cluster_index = total_labels[0:train_f2no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f2no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f2.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f2['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 2 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "#----fold3---------\r\n",
        "total_labels = AgglomerativeClustering(n_clusters=10,affinity='l1',linkage='single').fit_predict(train_f3no.append(test_f3no,ignore_index=True))\r\n",
        "\r\n",
        "train_cluster_index = total_labels[0:train_f3no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f3no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f3.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f3['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 3 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#----fold4---------\r\n",
        "total_labels = AgglomerativeClustering(n_clusters=10,affinity='l1',linkage='single').fit_predict(train_f4no.append(test_f4no,ignore_index=True))\r\n",
        "\r\n",
        "train_cluster_index = total_labels[0:train_f4no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f4no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f4.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f4['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 4 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "#----fold5---------\r\n",
        "total_labels = AgglomerativeClustering(n_clusters=10,affinity='l1',linkage='single').fit_predict(train_f5no.append(test_f5no,ignore_index=True))\r\n",
        "\r\n",
        "train_cluster_index = total_labels[0:train_f5no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f5no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f5.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f5['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 5 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mae Fold 1 :  0.8037710220168129\n",
            "Mae Fold 2 :  0.8165433049084527\n",
            "Mae Fold 3 :  0.8221479838133668\n",
            "Mae Fold 4 :  0.8213111920938856\n",
            "Mae Fold 5 :  0.8350883886079955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZTNaCyLtoLH",
        "outputId": "05642e13-674a-4e33-f714-7620c79af345"
      },
      "source": [
        "#agglomerative clustering l2 norm\r\n",
        "from sklearn.cluster import AgglomerativeClustering\r\n",
        "#everything else same\r\n",
        "#----fold1---------\r\n",
        "total_labels = AgglomerativeClustering(n_clusters=10,affinity='l2',linkage='average').fit_predict(train_f1no.append(test_f1no,ignore_index=True))\r\n",
        "\r\n",
        "train_cluster_index = total_labels[0:train_f1no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f1no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f1.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f1['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 1 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#----fold2---------\r\n",
        "\r\n",
        "total_labels = AgglomerativeClustering(n_clusters=10,affinity='l2',linkage='average').fit_predict(train_f2no.append(test_f2no,ignore_index=True))\r\n",
        "\r\n",
        "train_cluster_index = total_labels[0:train_f2no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f2no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f2.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f2['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 2 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "#----fold3---------\r\n",
        "total_labels = AgglomerativeClustering(n_clusters=10,affinity='l2',linkage='average').fit_predict(train_f3no.append(test_f3no,ignore_index=True))\r\n",
        "\r\n",
        "train_cluster_index = total_labels[0:train_f3no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f3no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f3.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f3['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 3 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#----fold4---------\r\n",
        "total_labels = AgglomerativeClustering(n_clusters=10,affinity='l2',linkage='average').fit_predict(train_f4no.append(test_f4no,ignore_index=True))\r\n",
        "\r\n",
        "train_cluster_index = total_labels[0:train_f4no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f4no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f4.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f4['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 4 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "#----fold5---------\r\n",
        "total_labels = AgglomerativeClustering(n_clusters=10,affinity='l2',linkage='average').fit_predict(train_f5no.append(test_f5no,ignore_index=True))\r\n",
        "\r\n",
        "train_cluster_index = total_labels[0:train_f5no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f5no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f5.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f5['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 5 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mae Fold 1 :  0.8485258144924133\n",
            "Mae Fold 2 :  0.8584694952464074\n",
            "Mae Fold 3 :  0.8643877595451679\n",
            "Mae Fold 4 :  0.865373654732918\n",
            "Mae Fold 5 :  0.879350842522081\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hzy3w07Vri5K",
        "outputId": "8dec8563-2ed7-4435-ba6c-5ebce90c6b67"
      },
      "source": [
        "# optics with minkowski as metric\r\n",
        "\r\n",
        "from sklearn.cluster import OPTICS\r\n",
        "\r\n",
        "#-----fold1----------\r\n",
        "total_labels = OPTICS(min_samples=5,metric='minkowski').fit_predict(train_f1no.append(test_f1no,ignore_index=True))\r\n",
        "#rest same\r\n",
        "train_cluster_index = total_labels[0:train_f1no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f1no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f1.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f1['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 1 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#---------------fold2------------\r\n",
        "\r\n",
        "#-----fold1----------\r\n",
        "total_labels = OPTICS(min_samples=5,metric='minkowski').fit_predict(train_f2no.append(test_f2no,ignore_index=True))\r\n",
        "\r\n",
        "train_cluster_index = total_labels[0:train_f2no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f2no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f2.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f2['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 2 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "#-------------fold3-------------\r\n",
        "\r\n",
        "\r\n",
        "total_labels = OPTICS(min_samples=5,metric='minkowski').fit_predict(train_f3no.append(test_f3no,ignore_index=True))\r\n",
        "\r\n",
        "train_cluster_index = total_labels[0:train_f3no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f3no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f3.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f3['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 3 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#-----fold4----------\r\n",
        "total_labels = OPTICS(min_samples=5,metric='minkowski').fit_predict(train_f4no.append(test_f4no,ignore_index=True))\r\n",
        "\r\n",
        "train_cluster_index = total_labels[0:train_f4no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f4no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f4.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f4['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 4 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#-----fold5----------\r\n",
        "total_labels = OPTICS(min_samples=5,metric='minkowski').fit_predict(train_f5no.append(test_f5no,ignore_index=True))\r\n",
        "\r\n",
        "train_cluster_index = total_labels[0:train_f5no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f5no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f5.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f5['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 5 : ',mae_sum/mae_cnt)\r\n",
        "\r\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mae Fold 1 :  0.8591594161851399\n",
            "Mae Fold 2 :  0.8782710961251048\n",
            "Mae Fold 3 :  0.8832249867762779\n",
            "Mae Fold 4 :  0.8780680009480718\n",
            "Mae Fold 5 :  0.8897481410197657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAqdc3AFB5tw",
        "outputId": "2151abbd-c06e-45ad-e348-4af8d58f7caf"
      },
      "source": [
        "#ward clustering with euclidean\r\n",
        "from sklearn.cluster import AgglomerativeClustering\r\n",
        "\r\n",
        "#----fold1---------\r\n",
        "#just the model changes rest same\r\n",
        "total_labels = AgglomerativeClustering(n_clusters=10,affinity='euclidean',linkage='ward').fit_predict(train_f1no.append(test_f1no,ignore_index=True))\r\n",
        "\r\n",
        "train_cluster_index = total_labels[0:train_f1no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f1no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f1.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f1['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 1 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#----fold2---------\r\n",
        "\r\n",
        "total_labels = AgglomerativeClustering(n_clusters=10,affinity='euclidean',linkage='ward').fit_predict(train_f2no.append(test_f2no,ignore_index=True))\r\n",
        "\r\n",
        "train_cluster_index = total_labels[0:train_f2no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f2no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f2.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f2['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 2 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "#----fold3---------\r\n",
        "total_labels = AgglomerativeClustering(n_clusters=10,affinity='euclidean',linkage='ward').fit_predict(train_f3no.append(test_f3no,ignore_index=True))\r\n",
        "\r\n",
        "train_cluster_index = total_labels[0:train_f3no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f3no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f3.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f3['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 3 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#----fold4---------\r\n",
        "total_labels = AgglomerativeClustering(n_clusters=10,affinity='euclidean',linkage='ward').fit_predict(train_f4no.append(test_f4no,ignore_index=True))\r\n",
        "\r\n",
        "train_cluster_index = total_labels[0:train_f4no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f4no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f4.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f4['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 4 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "#----fold5---------\r\n",
        "total_labels = AgglomerativeClustering(n_clusters=10,affinity='euclidean',linkage='ward').fit_predict(train_f5no.append(test_f5no,ignore_index=True))\r\n",
        "\r\n",
        "train_cluster_index = total_labels[0:train_f5no.shape[0]]\r\n",
        "test_cluster_index = total_labels[train_f5no.shape[0]:]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f5.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f5['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 5 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mae Fold 1 :  0.8431583275095874\n",
            "Mae Fold 2 :  0.8515385811787766\n",
            "Mae Fold 3 :  0.8627318273155296\n",
            "Mae Fold 4 :  0.862890701972968\n",
            "Mae Fold 5 :  0.8773060894180568\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29PXF1noERLs",
        "outputId": "f15ea2a9-1b91-44f0-9d3b-2c626a529c0f"
      },
      "source": [
        "#Birch clustering \r\n",
        "#from sklearn doc\r\n",
        "from sklearn.cluster import Birch\r\n",
        "\r\n",
        "#fold1\r\n",
        "#just fitted model changes\r\n",
        "fitted_model = Birch(n_clusters=10,threshold=0.25,compute_labels=True).fit(train_f1)\r\n",
        "\r\n",
        "#train_cluster_index has the cluster numbers for the training data(users)\r\n",
        "train_cluster_index = fitted_model.predict(train_f1)\r\n",
        "#test_cluster_index has the cluster numbers for the test data(users)\r\n",
        "test_cluster_index = fitted_model.predict(test_f1)\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "#go through test data\r\n",
        "for i in range(1,test_f1.shape[0]+1):\r\n",
        "  #for each item J\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      #ignore ratings which is not present in u.data\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    #go through each training user \r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #found user at index k in our cluster\r\n",
        "        #get user_id of user at index k \r\n",
        "        user_id = train_f1['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          #if our neighbour in our cluster has rated item J then use in finding average\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    #initialize predicted rating as 3 to minimize mae\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 1 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#same thing for fold 2 only thing is train_f1 is replaced by train_f2 and test_f1-->test_f2\r\n",
        "#repeat for 5 folds\r\n",
        "#-------------fold2--------------\r\n",
        "\r\n",
        "fitted_model = Birch(n_clusters=10,threshold=0.25,compute_labels=True).fit(train_f2)\r\n",
        "train_cluster_index = fitted_model.predict(train_f2)\r\n",
        "test_cluster_index = fitted_model.predict(test_f2)\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(1,test_f2.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f2['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 2 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#-----------------fold3--------------------\r\n",
        "\r\n",
        "fitted_model = Birch(n_clusters=10,threshold=0.25,compute_labels=True).fit(train_f3)\r\n",
        "train_cluster_index = fitted_model.predict(train_f3)\r\n",
        "test_cluster_index = fitted_model.predict(test_f3)\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(1,test_f3.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f3['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 3 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#------fold 4--------------\r\n",
        "\r\n",
        "fitted_model = Birch(n_clusters=10,threshold=0.25,compute_labels=True).fit(train_f4)\r\n",
        "train_cluster_index = fitted_model.predict(train_f4)\r\n",
        "test_cluster_index = fitted_model.predict(test_f4)\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(1,test_f4.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f4['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 4 : ',mae_sum/mae_cnt)\r\n",
        "\r\n",
        "\r\n",
        "#----------F5---------\r\n",
        "\r\n",
        "fitted_model = Birch(n_clusters=10,threshold=0.25,compute_labels=True).fit(train_f5)\r\n",
        "train_cluster_index = fitted_model.predict(train_f5)\r\n",
        "test_cluster_index = fitted_model.predict(test_f5)\r\n",
        "\r\n",
        "\r\n",
        "#calculate ratings for each test user based on cluster\r\n",
        "#user will be given avg rating of his cluster\r\n",
        "#then calculate mae between predicted and actual rating present in u.data\r\n",
        "mae_sum=0\r\n",
        "mae_cnt=0\r\n",
        "for i in range(1,test_f5.shape[0]+1):\r\n",
        "  for j in range(1,1683):\r\n",
        "    if(np.isnan(ratings[i][j])==True):\r\n",
        "      continue\r\n",
        "    #calculate avg rating for item J in cluster of user I\r\n",
        "    avg_rating=0\r\n",
        "    avg_cnt=0\r\n",
        "    for k in range(len(train_cluster_index)):\r\n",
        "      if(test_cluster_index[i-1] == train_cluster_index[k]):\r\n",
        "        #get user_id of cluster neighbor\r\n",
        "        user_id = train_f5['user_id'][k]\r\n",
        "        if(np.isnan(ratings[user_id][j])==False):\r\n",
        "          avg_rating+=(ratings[user_id][j])\r\n",
        "          avg_cnt+=1\r\n",
        "    predicted_rating = 3\r\n",
        "    if(avg_cnt>0):\r\n",
        "      predicted_rating = avg_rating/avg_cnt\r\n",
        "    #check mae\r\n",
        "    mae_sum += abs(predicted_rating - ratings[i][j])\r\n",
        "    mae_cnt+=1\r\n",
        "print('Mae Fold 5 : ',mae_sum/mae_cnt)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mae Fold 1 :  0.8434641289316437\n",
            "Mae Fold 2 :  0.8477921690601621\n",
            "Mae Fold 3 :  0.8617299713450177\n",
            "Mae Fold 4 :  0.8679531042342076\n",
            "Mae Fold 5 :  0.8678696667142268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBv9lHdFDX_c"
      },
      "source": [
        "#Birch clustering\r\n",
        "#from sklearn docs\r\n",
        "from sklearn.cluster import Birch\r\n",
        "#---fold1------\r\n",
        "fitted_model = Birch(n_clusters=10,threshold=0.25,compute_labels=True).fit(train_f1no)\r\n",
        "\r\n",
        "train_cluster_index = fitted_model.predict(train_f1no)\r\n",
        "test_cluster_index = fitted_model.predict(train_f1no)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}